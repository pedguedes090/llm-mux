# llm-mux

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Platform](https://img.shields.io/badge/platform-macOS%20%7C%20Linux%20%7C%20Windows-blue)](https://github.com/nghyane/llm-mux)
[![Go Version](https://img.shields.io/badge/go-1.24-cyan)](https://golang.org)

**The Universal AI Gateway.** Access Gemini, Claude, OpenAI, GitHub Copilot, Kiro, and more through a single local API. No API keys required‚Äîjust OAuth.

```mermaid
graph LR
    User[Your App/CLI] -->|OpenAI/Claude Format| Mux[llm-mux]
    Mux -->|OAuth| Google[Gemini 2.5/3.0]
    Mux -->|OAuth| Anthropic[Claude 4/Sonnet]
    Mux -->|OAuth| GitHub[GPT-4.1/5]
    Mux -->|OAuth| Amazon[Kiro/Q]
    Mux -->|OAuth| Others[Qwen/iFlow]
```

## ‚ö°Ô∏è Quick Install

Get up and running in seconds. The installer sets up the binary and a background service automatically.

| OS | Command |
|:---|:---|
| **macOS / Linux** | `curl -fsSL https://raw.githubusercontent.com/nghyane/llm-mux/main/install.sh \| bash` |
| **Windows** (PowerShell) | `irm https://raw.githubusercontent.com/nghyane/llm-mux/main/install.ps1 \| iex` |
| **Docker** | `docker run -p 8318:8318 -v ~/.config/llm-mux:/root/.config/llm-mux nghyane/llm-mux` |

### First Run Setup

After installing, initialize your config and generate a management key:

```bash
llm-mux --init          # Creates config + generates management key
llm-mux --init --force  # Regenerate management key
```

The management key is stored in `~/.config/llm-mux/credentials.json` and is required for the Web UI.

---

## üîê Authentication

Authenticate once, use forever. Tokens are auto-refreshed.

```bash
# Google / Gemini
llm-mux --login              # Gemini Pro/Flash/2.5/3.0
llm-mux --antigravity-login  # Google Cloud Code (Antigravity)

# Anthropic
llm-mux --claude-login       # Claude 4/Sonnet/Opus

# OpenAI / GitHub
llm-mux --codex-login        # OpenAI Codex CLI
llm-mux --copilot-login      # GitHub Copilot (GPT-4.1, GPT-5)

# Amazon
llm-mux --kiro-login         # Kiro / Amazon Q

# Others
llm-mux --qwen-login         # Qwen / Alibaba
llm-mux --iflow-login        # iFlow
```

You can also authenticate via the **Web UI** at `http://localhost:8318/v0/management/` (requires management key from `--init`).

---

## üöÄ Usage

`llm-mux` runs on `http://localhost:8318`. Point **any** AI client (Cursor, VS Code, Python, LangChain) to this URL.

### Example: Using OpenAI Format (Universal)
You can call *any* model using the standard OpenAI format:

```bash
curl http://localhost:8318/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "gemini-2.5-flash",
    "messages": [{"role": "user", "content": "Explain quantum computing in one sentence."}]
  }'
```

### Available Models (Examples)

| Provider | Models |
|:---|:---|
| **Gemini** | `gemini-2.5-pro`, `gemini-2.5-flash`, `gemini-3-flash-preview` |
| **Claude** | `claude-sonnet-4-20250514`, `claude-3-5-sonnet`, `claude-3-opus` |
| **Copilot** | `gpt-4.1`, `gpt-4o`, `gpt-5-mini`, `gpt-5.1-codex-max` |
| **Kiro** | `amazon-q-developer` |

> **Tip:** List all available models with `curl http://localhost:8318/v1/models`

### Supported API Endpoints
| Standard | Endpoint URL | Use Case |
|:---|:---|:---|
| **OpenAI** | `/v1/chat/completions` | Most apps, LangChain, AutoGen |
| **Anthropic** | `/v1/messages` | Cursor, Claude Dev, Aider |
| **Gemini** | `/v1beta/models/...` | Google ecosystem tools |
| **Ollama** | `/api/chat` | Local-first tools |

---

## üéõÔ∏è Management API & Web UI

llm-mux includes a built-in management interface for adding/removing auth credentials, viewing usage stats, and more.

**Web UI:** `http://localhost:8318/v0/management/`

**API Endpoints:**
```bash
# Start OAuth flow (returns auth URL)
curl -X POST http://localhost:8318/v0/management/oauth/start \
  -H "X-Management-Key: YOUR_KEY" \
  -d '{"provider": "claude"}'

# Check OAuth status
curl http://localhost:8318/v0/management/oauth/status/STATE \
  -H "X-Management-Key: YOUR_KEY"

# List all auth credentials
curl http://localhost:8318/v0/management/auths \
  -H "X-Management-Key: YOUR_KEY"
```

The management key is generated by `llm-mux --init` and stored in `~/.config/llm-mux/credentials.json`.
You can also set `MANAGEMENT_PASSWORD` environment variable to override.

---

## üõ†Ô∏è Advanced & Services

<details>
<summary><strong>üñ•Ô∏è Service Management (Start/Stop)</strong></summary>

| Action | macOS (`launchctl`) | Linux (`systemd`) | Windows (`Task Scheduler`) |
|:---|:---|:---|:---|
| **Start** | `launchctl start com.llm-mux` | `systemctl --user start llm-mux` | `Start-ScheduledTask "Start llm-mux"` |
| **Stop** | `launchctl stop com.llm-mux` | `systemctl --user stop llm-mux` | `Stop-ScheduledTask "Start llm-mux"` |
| **Logs** | `~/.local/var/log/llm-mux.log` | `journalctl --user -u llm-mux` | Windows Event Viewer |

</details>

<details>
<summary><strong>‚òÅÔ∏è Sync Config with GitStore (Pro)</strong></summary>

Sync your tokens and config across multiple machines using a private Git repo.

1. Create a private empty repo on GitHub.
2. Set environment variables (in `.bashrc` or Windows Env):
   ```bash
   export GITSTORE_GIT_URL=https://github.com/username/my-mux-store.git
   export GITSTORE_GIT_USERNAME=your_user
   export GITSTORE_GIT_TOKEN=your_pat_token
   ```
3. Restart `llm-mux`. It will auto-sync!
</details>

<details>
<summary><strong>üèóÔ∏è Architecture</strong></summary>

*   **Intermediate Representation (IR)**: Translates requests 2N times instead of N¬≤ times.
*   **Provider Adapters**: Handles specific OAuth flows and token rotation.
*   **Load Balancer**: Smart routing based on quota availability.
</details>

## License

MIT License - see [LICENSE](LICENSE)
